{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e810680c",
   "metadata": {},
   "source": [
    "# Reading and Writing CSV Files\n",
    "\n",
    "## Video 1: What are CSV Files\n",
    "CSVs\n",
    "+ Common input/output file type for programs  \n",
    "+ Text file, no non-printable characters  \n",
    "+ Easy to work with programmatically\n",
    "\n",
    "## Video 2: Reading CSVs with Python's `csv` Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cec0719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are name, department, birthday month\n",
      "\tJohn Smith works in the Accounting department, and was born in November.\n",
      "\tErica Meyers works in the IT department, and was born in March.\n",
      "Processed 3 lines\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "#first we open the file\n",
    "with open('employee_birthday.csv') as csv_file:\n",
    "    \n",
    "    #Next we have to create the reader\n",
    "    csv_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "    line_count = 0 \n",
    "    for row in csv_reader:\n",
    "        # first line should contain column names\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            # rest of the lines contain data\n",
    "            print(f'\\t{row[0]} works in the {row[1]} department, and was born in {row[2]}.')\n",
    "            line_count += 1\n",
    "            \n",
    "    # Summary of what was read in\n",
    "    print(f'Processed {line_count} lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb349f7f",
   "metadata": {},
   "source": [
    "The CSV module also allows you to use `.DictReader` you'll be able to use column names. `.DictReader` assumes that first row is a header. This is easier to use and can be helpful if you have more columns or if you need to filter out columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cbf7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are name, department, birthday month\n",
      "\tJohn Smith works in the Accounting department, and was born in November.\n",
      "\tErica Meyers works in the IT department, and was born in March.\n",
      "Processed 3 lines\n"
     ]
    }
   ],
   "source": [
    "#first we open the file\n",
    "with open('employee_birthday.csv') as csv_file:\n",
    "    \n",
    "    csv_reader = csv.DictReader(csv_file, delimiter=\",\")\n",
    "    line_count = 0 \n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        print(f'\\t{row[\"name\"]} works in the {row[\"department\"]} department, and was born in {row[\"birthday month\"]}.')\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c2519",
   "metadata": {},
   "source": [
    "## Video 3: Advanced CSV Reader Parameters\n",
    "What about non-standard files.\n",
    "\n",
    "What if you want to read a file that has a comma in the data field, such as addresses. There are a few ways around this:  \n",
    "1) Use a different delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95d9d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are name, address, date joined\n",
      "\tjohn smith lives at 1132 Anywhere Lane Hoboken NJ, 07030 and joined on Jan 4.\n",
      "\terica meyers lives at 1234 Anywhere Lane Hoboken JN, 07030 and joined on March 2.\n",
      "Processed 3 lines\n"
     ]
    }
   ],
   "source": [
    "with open('different_delim.csv') as csv_file:\n",
    "    \n",
    "    csv_reader = csv.DictReader(csv_file, delimiter=\"|\")\n",
    "    line_count = 0 \n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        print(f'\\t{row[\"name\"]} lives at {row[\"address\"]} and joined on {row[\"date joined\"]}.')\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d6d92",
   "metadata": {},
   "source": [
    "2) Wrap the data in quotes and use the `quotechar` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b12b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are name, address, date joined\n",
      "\tjohn smith lives at 1132 Anywhere Lane Hoboken NJ, 07030 and joined on Jan 4.\n",
      "\terica meyers lives at 1234 Anywhere Lane Hoboken JN, 07030 and joined on March 2.\n",
      "Processed 3 lines\n"
     ]
    }
   ],
   "source": [
    "with open('quote_wrapping.csv') as csv_file:\n",
    "    \n",
    "    csv_reader = csv.DictReader(csv_file, delimiter=\"|\", quotechar = '\"')\n",
    "    line_count = 0 \n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        print(f'\\t{row[\"name\"]} lives at {row[\"address\"]} and joined on {row[\"date joined\"]}.')\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b5b39",
   "metadata": {},
   "source": [
    "3) use an escape character. Use the `escapechar` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "078bbdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are name, address, date joined\n",
      "\tjohn smith lives at 1132 Anywhere Lane Hoboken NJ, 07030 and joined on Jan 4.\n",
      "\terica meyers lives at 1234 Anywhere Lane Hoboken JN, 07030 and joined on March 2.\n",
      "Processed 3 lines\n"
     ]
    }
   ],
   "source": [
    "with open('escape_char.csv') as csv_file:\n",
    "    \n",
    "    csv_reader = csv.DictReader(csv_file, delimiter=\",\", escapechar=\"|\")\n",
    "    line_count = 0 \n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        print(f'\\t{row[\"name\"]} lives at {row[\"address\"]} and joined on {row[\"date joined\"]}.')\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b42efd",
   "metadata": {},
   "source": [
    "## Video 4: Writing CSVs with Python's `csv` module\n",
    "You can write csvs line by line or by using dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cdfffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('employee_file.csv', mode='w') as employee_file:\n",
    "    # we need to create a writer\n",
    "    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    \n",
    "    # Now we write individual lines\n",
    "    employee_writer.writerow(['John Smith', 'Accounting', 'November'])\n",
    "    employee_writer.writerow(['Erica Meyers', 'IT', 'March'])\n",
    "  \n",
    "# This created a file in the local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd566d5",
   "metadata": {},
   "source": [
    "Quoteminimal only puts quotes if they are contained within the data. SOme other options include:  \n",
    "+ QUOTE_ALL: puts all fields in quotes\n",
    "+ QUOTE_NONNUMERIC: Only puts quotes around non-numeric fields\n",
    "+ QUOTE_NONE: Won't add any quotes. Will need add in an escape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fffadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('employee_file_QUOTE_NONE.csv', mode='w') as employee_file:\n",
    "    # we need to create a writer\n",
    "    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting = csv.QUOTE_NONE, escapechar = '|')\n",
    "    \n",
    "    \n",
    "    # Now we write individual lines\n",
    "    employee_writer.writerow(['John, Smith', 'Accounting', 'November'])\n",
    "    employee_writer.writerow(['Eric, Meyers', 'IT', 'March'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6df6b6",
   "metadata": {},
   "source": [
    "You can also write a csv using a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25737967",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('employee_file_dict.csv', mode='w') as employee_file:\n",
    "    # we need to create a field names\n",
    "    fieldnames = ['name', 'dept', 'birth_month']\n",
    "    employee_writer = csv.DictWriter(employee_file, fieldnames=fieldnames)\n",
    "    \n",
    "    # Then we need to write the header row\n",
    "    employee_writer.writeheader()\n",
    "    # Now we write individual lines using a dict\n",
    "    employee_writer.writerow({'name': 'John Smith', 'dept': 'Accounting', 'birth_month': 'November'})\n",
    "    employee_writer.writerow({'name':'Erica Meyers', 'dept':'IT', 'birth_month':'March'})\n",
    "  \n",
    "# This created a file in the local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09678e9",
   "metadata": {},
   "source": [
    "## Reading CSVs With Pandas\n",
    "Pandas is short for panel data\n",
    "\n",
    "To load a csv simply use the `pd.read_cv()` method. It treats the first rows as headers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "994195e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name Hire Date   Salary  Sick Days remaining\n",
      "0  Graham Chapman  03/15/14  50000.0                   10\n",
      "1     John Cleese  06/01/15  65000.0                    8\n",
      "2       Eric Idle  05/12/14  45000.0                   10\n",
      "3     Terry Jones  11/01/13  70000.0                    3\n",
      "4   Terry Gilliam  08/12/14  48000.0                    7\n",
      "5   Michael Palin  05/23/13  66000.0                    8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('hrdata.csv')\n",
    "print(df)\n",
    "type(df['Hire Date'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba448f0",
   "metadata": {},
   "source": [
    "If we want to change the index to the name column. It's also worth noting that the hire date is a string. We can change that using the parse_dates parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33fb7b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Hire Date   Salary  Sick Days remaining\n",
      "Name                                                   \n",
      "Graham Chapman 2014-03-15  50000.0                   10\n",
      "John Cleese    2015-06-01  65000.0                    8\n",
      "Eric Idle      2014-05-12  45000.0                   10\n",
      "Terry Jones    2013-11-01  70000.0                    3\n",
      "Terry Gilliam  2014-08-12  48000.0                    7\n",
      "Michael Palin  2013-05-23  66000.0                    8\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hrdata.csv', index_col='Name', parse_dates=['Hire Date'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022907b",
   "metadata": {},
   "source": [
    "We can do further customization as well. The example below will change the headers rather than using the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9e4754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Hired   Salary  Sick Days\n",
      "Employee                                     \n",
      "Graham Chapman 2014-03-15  50000.0         10\n",
      "John Cleese    2015-06-01  65000.0          8\n",
      "Eric Idle      2014-05-12  45000.0         10\n",
      "Terry Jones    2013-11-01  70000.0          3\n",
      "Terry Gilliam  2014-08-12  48000.0          7\n",
      "Michael Palin  2013-05-23  66000.0          8\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hrdata.csv',\n",
    "                 index_col='Employee', # notice referencing the new headers\n",
    "                 parse_dates=['Hired'],\n",
    "                 header=0, # THis tells python to ignore the header row\n",
    "                 names=['Employee', 'Hired', 'Salary', 'Sick Days'] #providing new header names\n",
    "                )\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a407a7",
   "metadata": {},
   "source": [
    "## Writing CSVs with Pandas\n",
    "Lets modify the df dataframe and write out another csv. Adding a row is done by specifying the index (name) inside square brackets and then providing a list for the other columns.  \n",
    "\n",
    "Writing a CSV is as simple as using the `.to_csv()` method and specifying a new file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94a87480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Hired   Salary  Sick Days\n",
      "Employee                                               \n",
      "Graham Chapman  2014-03-15 00:00:00  50000.0         10\n",
      "John Cleese     2015-06-01 00:00:00  65000.0          8\n",
      "Eric Idle       2014-05-12 00:00:00  45000.0         10\n",
      "Terry Jones     2013-11-01 00:00:00  70000.0          3\n",
      "Terry Gilliam   2014-08-12 00:00:00  48000.0          7\n",
      "Michael Palin   2013-05-23 00:00:00  66000.0          8\n",
      "Cookie Cat               2016-07-04  20000.0          0\n"
     ]
    }
   ],
   "source": [
    "df.loc['Cookie Cat']= ['2016-07-04', 20000.00, 0]\n",
    "print(df)\n",
    "\n",
    "df.to_csv('hrdata_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e76c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d925d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
